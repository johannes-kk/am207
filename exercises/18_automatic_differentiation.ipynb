{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of 18-automatic-differentiation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/johannes-kk/am207/blob/master/exercises/18_automatic_differentiation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWdYQ3mjNoXS"
      },
      "source": [
        "# DAY 18: Automatic Differentiation \n",
        "\n",
        "### AM207: Advanced Scientific Computing\n",
        "\n",
        "#### Instructor: Weiwei Pan\n",
        "\n",
        "#### Due: November 3rd, 11:59pm EST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x27kWg2dNo7s"
      },
      "source": [
        "**Names of Group Members**: \n",
        "- Matthieu Meeus (matthieu_meeus@g.harvard.edu)\n",
        "- Nari Johnson njohnson@college.harvard.edu\n",
        "- Will Seaton (wseaton@g.harvard.edu)\n",
        "- Maggie Wang (maggiewang@college.harvard.edu)\n",
        "- Johannes Kolberg (johanneskolberg@g.harvard.edu)\n",
        "- Alex Spiride (aspiride@college.harvard.edu)‚Ä©"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ATiLknorOb-l"
      },
      "source": [
        "## Learning Goals:\n",
        "\n",
        "1. Gain intuition for how to perform reverse and forward mode auto-differentiation.\n",
        "2. Implement forward-mode auto-differentiation.\n",
        "\n",
        "\n",
        "### Load necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2aG7tFRPh2v6"
      },
      "source": [
        "### Import basic libraries\n",
        "import numpy as np\n",
        "import math\n",
        "import pdb\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPFwep8g0Tok"
      },
      "source": [
        "## Problem 1: Forward versus Backwards Differentiation\n",
        "\n",
        "In this problem, you'll run through forwards and backwards differentiation for a simple computational graph by hand. These paper-and-pencil exercises are extremely important to do before you sit down to implement anything. We'll work with the same computational graph as in the lecture: $y = f(x_1, x_2) = \\ln(x_1) + x_1x_2 - \\sin(x_2)$\n",
        "\n",
        "<img src=\"https://i.ibb.co/tPKRYf7/computation-graph.jpg\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UCaXFAaXJrL1"
      },
      "source": [
        "**Exercise 1:** Compute $\\nabla_{\\mathrm{x}}f\\vert_{x_1=1, x_2=2}$ using forward-mode differentiation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ouvVp8hYeu3E"
      },
      "source": [
        "**Answer:**\n",
        "\n",
        "Let's write out the evaluation trace and compute the derivative with respect to $x_1$:\n",
        "\n",
        "\\begin{equation*} \\begin{aligned}[c] v_{-1} & = x_1 &= 1 \\\\ v_{0} &= x_2 &= 2 \\\\ v_1 &= \\ln v_{-1} &= \\ln 1 \\\\ v_2 &= v_{-1} \\times v_0 &= 1 \\times 2 \\\\ v_3 &= \\sin v_0 &= \\sin 2 \\\\ v_4 &= v_1 + v_2 &= 0 + 2 \\\\ v_5 &= v_4 - v_3 &= 2 - 0.909 \\\\ y &= v_5 &= 1.091 \\end{aligned} \\qquad\\Longleftrightarrow\\qquad \\begin{aligned}[c] \n",
        " \\dot{v}_{-1} & = \\dot{x}_1 &= 1 \\\\ \\dot{v}_{0} &= \\dot{x}_2 &= 0 \\\\ \\dot{v}_1 &= \\frac{\\dot{v}_{-1}}{v_{-1}}  &= 1 \\\\ \\dot{v}_{2} = \\dot{v}_{-1}*v_0 + \\dot{v}_0*v_{-1}  &= 2 \\\\ \\dot{v}_{3} &= \\dot{v}_{0}*\\cos v_0 &= 0 \\\\ \\dot{v}_{4} &= \\dot{v}_1 + \\dot{v}_2 &= 3 \\\\  \\dot{v}_5 &= \\dot{v}_4 - \\dot{v}_3 &= 3 \\\\ \\dot{y} &= \\dot{v}_5 &= 3\n",
        " \\end{aligned} \\end{equation*}\n",
        "\n",
        "\n",
        "For the derivative with respect to $x_2$, we get:\n",
        "\n",
        "\\begin{equation*} \\begin{aligned}[c] v_{-1} & = x_1 &= 1 \\\\ v_{0} &= x_2 &= 2 \\\\ v_1 &= \\ln v_{-1} &= \\ln 1 \\\\ v_2 &= v_{-1} \\times v_0 &= 1 \\times 2 \\\\ v_3 &= \\sin v_0 &= \\sin 2 \\\\ v_4 &= v_1 + v_2 &= 0 + 2 \\\\ v_5 &= v_4 - v_3 &= 2 - 0.909 \\\\ y &= v_5 &= 1.091 \\end{aligned} \\qquad\\Longleftrightarrow\\qquad \\begin{aligned}[c]  \\dot{v}_{-1} & = \\dot{x}_1 &= 0‚Ä®\\\\ \\dot{v}_{0} &= \\dot{x}_2 &= 1‚Ä®\\\\ \\dot{v}_1 &= \\frac{\\dot{v}_{-1}}{v_{-1}}  &= 0‚Ä®\\\\ \\dot{v}_{2} = \\dot{v}_{-1}*v_0 + \\dot{v}_0*v_{-1}  &= 0 + 1*1 = 1 ‚Ä®\\\\ \\dot{v}_{3} &= \\dot{v}_{0}*\\cos v_0 &= cos(2)‚Ä®\\\\ \\dot{v}_{4} &= \\dot{v}_1 + \\dot{v}_2 &= 1 ‚Ä®\\\\ v_5 &= \\dot{v}_4 - \\dot{v}_3 &= 1  - cos(2)‚Ä®\\\\ y &= v_5 &= 1 -cos(2) = 1.416 \\end{aligned} \\end{equation*}\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDXDTxiIaJp2"
      },
      "source": [
        "**Exercise 2:** Compute $\\nabla_{\\mathrm{x}}f\\vert_{x_1=1, x_2=2}$ using reverse-mode differentiation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bOHOLcZBj2hw"
      },
      "source": [
        "**Answer:**\n",
        "\n",
        "\\begin{equation*}\n",
        "\\begin{aligned}[c]\n",
        "v_{-1} & = x_1 &= 1 \\\\\n",
        "v_{0} &= x_2 &= 2 \\\\\n",
        "v_1 &= \\ln v_{-1} &= \\ln 1 \\\\\n",
        "v_2 &= v_{-1} \\times v_0 &= 1 \\times 2 \\\\\n",
        "v_3 &= \\sin v_0 &= \\sin 2 \\\\\n",
        "v_4 &= v_1 + v_2 &= 0 + 2 \\\\\n",
        "v_5 &= v_4 - v_3 &= 2 - 0.909 \\\\\n",
        "y &= v_5 &= 1.091\n",
        "\\end{aligned}\n",
        "\\qquad\\Longleftrightarrow\\qquad\n",
        "\\begin{aligned}[c]\n",
        "\\bf{\\bar{x}_1} &= \\bf{\\bar{v}_{-1}} &= \\bf{3}\\\\\n",
        "\\bf{\\bar{x}_2} &= \\bf{\\bar{v}_{0}} &= \\bf{1.416}\\\\\n",
        "\\bar{v}_{-1} &= \\bar{v}_{-1} + \\bar{v}_1 \\frac{\\partial v_1}{\\partial v_{0}} &= \\bar{v}_{-1} + \\bar{v}_1 / v_{-1} &= 3 \\\\\n",
        "\\bar{v}_{0} &= \\bar{v}_0 + \\bar{v}_2 \\frac{\\partial v_2}{\\partial v_{0}} &= \\bar{v}_0 + \\bar{v}_2 \\times v_{-1} &= 1.416 \\\\\n",
        "\\bar{v}_{-1} &= \\bar{v}_2 \\frac{\\partial v_2}{\\partial v_{-1}} &= \\bar{v}_2 \\times v_0 &= 2 \\\\\n",
        "\\bar{v_0} &= \\bar{v_3} \\frac{\\partial v_3}{\\partial v_0} &= \\bar{v}_3 \\times \\cos v_0 &= 0.416 \\\\\n",
        "\\bar{v_2} &= \\bar{v_4} \\frac{\\partial v_4}{\\partial v_2} &= \\bar{v}_4 \\times 1 &= 1 \\\\\n",
        "\\bar{v_1} &= \\bar{v_4} \\frac{\\partial v_4}{\\partial v_1} &= \\bar{v}_4 \\times 1 &= 1 \\\\\n",
        "\\bar{v_3} &= \\bar{v_5} \\frac{\\partial v_5}{\\partial v_3} &= \\bar{v}_5 \\times (-1) &= -1 \\\\\n",
        "\\bar{v_4} &= \\bar{v_5} \\frac{\\partial v_5}{\\partial v_4} &= \\bar{v}_5 \\times 1 &= 1 \\\\\n",
        "\\bar{v_5} &= \\bar{y} &= 1\n",
        "\\end{aligned}\n",
        "\\end{equation*}\n",
        "‚Ä©"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxrLACL0iF7v"
      },
      "source": [
        "**Exercise 3:** What are the pros and cons of each mode of differentiation? Describe a concrete set of circumstance where it would be more appropriate to use forwar-mode differentiation. Do the same for reverse mode."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4smT6EcZf6O8"
      },
      "source": [
        "**Answer:**\n",
        "\n",
        "In forward mode, you only require a single forward pass to calculate both intermediate values and partial derivatives. In reverse mode, you require two passes to first calculate intermediate values then reverse to calculate partial derivatives. However, reverse mode calculations are completely local, only requiring three per-step pieces of information: i) current value of $ùë£_ùëò$ ii) derivative of f with respect to every child $ùë£_ùëò$ iii) derivative of function $‚Ñé_ùë£$ describing how v depends on ùë£ùëò, which can be hard-coded. As a result, the trade-offs involve memory storage vs computation time. Forward mode is forward, but requires more memory. Reverse requires less memory, but takes longer due to its extra pass. It would be more appropriate to use forward-mode differentiation for an equation with fewer operations where speed matters. It would be better to use reverse-mode differentiation for more complex functions.‚Ä©\n",
        "\n",
        "Additionally, both methods have different computational complexity dependend on the number of input and output. For the forward pass, the number of sweeps required is proportional to the number of input variables, while for the backward pass this is proportional to the number of output variables. As such, it will be computationally better to use the backward pass if you have for instance only one output and multiple variables as input. One example is in a neural network, where you have a one-dimensional loss and you wish to compute the gradient of that loss with respect to a lot of weights. in this case, reverse mode will be the clear winner. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVOaTpkDiiaB"
      },
      "source": [
        "**Exercise 4:** Suppose we've implemented both forward and reverse mode differentiation. How do we compute second derivatives? For example, can we just run reverse (or forward mode) differentiation twice?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K93WYY7-mb3R"
      },
      "source": [
        "**Answer:**\n",
        "\n",
        "This definitely seems possible. If you can keep track of the operations needed to compute the first derivatives, you could just apply either the reverse or forward mode once again. \n",
        "\n",
        "-> this turns out to be wrong. You first need to compute the reverse and then the forward in order to compute second order derivatives. \n",
        "\n",
        "However, calculating the Hessian (second-order derivatives) is more complicated due to interactions between the variables. Our autodiff implementation can‚Äôt be applied directly as-is since the interactions add a third dimension to the matrix of calculations.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vRJX5tgXaPBy"
      },
      "source": [
        "## Problem 2: Implementing Forward Mode AutoDiff\n",
        "\n",
        "**Exercise 5:** Implement forward mode auto-differentiation for functions composed of 3 binary arithmetic operations (+, -, *) and four elementary functions (constant, power n, sin, ln).\n",
        "\n",
        "Verify that your implementation computes derivatives correctly by comparing the derivative your implementation of auto-diff computes versus the derivatives you compute by hand (or have Wolfram Alpha compute).\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-v5xi__9F41N"
      },
      "source": [
        "'''small example of reverse mode autodiff as implemented in https://github.com/Rufflewind/revad/'''\n",
        "class Var:\n",
        "    def __init__(self, value):\n",
        "        self.value = value\n",
        "        self.children = []\n",
        "        self.grad_value = None\n",
        "\n",
        "    def grad(self):\n",
        "        if self.grad_value is None:\n",
        "            self.grad_value = sum(weight * var.grad()\n",
        "                                  for weight, var in self.children)\n",
        "        return self.grad_value\n",
        "\n",
        "    #overloading the '+' operator\n",
        "    def __add__(self, other):\n",
        "        z = Var(self.value + other.value)\n",
        "        self.children.append((1.0, z))\n",
        "        other.children.append((1.0, z))\n",
        "        return z\n",
        "    \n",
        "    #overloading the '*' operator\n",
        "    def __mul__(self, other):\n",
        "        z = Var(self.value * other.value)\n",
        "        self.children.append((other.value, z))\n",
        "        other.children.append((self.value, z))\n",
        "        return z\n",
        "\n",
        "def sin(x):\n",
        "    z = Var(math.sin(x.value))\n",
        "    x.children.append((math.cos(x.value), z))\n",
        "    return z"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-3HBUN4nwPl",
        "outputId": "e4f701ab-f2d6-43cb-9130-1abb2c154230",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "'''small example of reverse mode autodiff as implemented in https://github.com/Rufflewind/revad/'''\n",
        "class Var:\n",
        "    def __init__(self, value):\n",
        "        self.value = value\n",
        "        self.children = []\n",
        "        self.grad_value = None\n",
        "\n",
        "    def grad(self):\n",
        "        if self.grad_value is None:\n",
        "            self.grad_value = sum(weight * var.grad()\n",
        "                                  for weight, var in self.children)\n",
        "        return self.grad_value\n",
        "\n",
        "    #overloading the '+' operator\n",
        "    def __add__(self, other):\n",
        "        z = Var(self.value + other.value)\n",
        "        self.children.append((1.0, z))\n",
        "        other.children.append((1.0, z))\n",
        "        return z\n",
        "    \n",
        "    #overloading the '*' operator\n",
        "    def __mul__(self, other):\n",
        "        z = Var(self.value * other.value)\n",
        "        self.children.append((other.value, z))\n",
        "        other.children.append((self.value, z))\n",
        "        return z\n",
        "\n",
        "    #overloading the '-' operator\n",
        "    def __sub__(self, other):\n",
        "        z = Var(self.value - other.value)\n",
        "        self.children.append((other.value, z))\n",
        "        other.children.append((self.value, z))\n",
        "        return z\n",
        "\n",
        "#define elementary function sin\n",
        "def sin(x):\n",
        "    z = Var(math.sin(x.value))\n",
        "    x.children.append((math.cos(x.value), z))\n",
        "    return z\n",
        "\n",
        "#define elementary function constant\n",
        "def const(x):\n",
        "    z = Var(x.value)\n",
        "    x.children.append((0, z))\n",
        "    return z\n",
        "\n",
        "#define elementary function power n\n",
        "def pow(x, n):\n",
        "    z = Var(x.value**n)\n",
        "    x.children.append((n*x.value, z))\n",
        "    return z\n",
        "\n",
        "#define elementary function ln\n",
        "def log(x):\n",
        "    z = Var(math.log(x.value))\n",
        "    x.children.append((1 / x.value, z))\n",
        "    return z\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "value of x-y + pow(x,3) evaluated at x=0.5, y=4.2: -3.575\n",
            "forward pass of our implementation: -3.575\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOdWfhZToBPF",
        "outputId": "05240e59-8ece-47b3-baee-1fcdcf3179c7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# New example\n",
        "x = Var(0.5)\n",
        "y = Var(4.2)\n",
        "z = const(x-y) + pow(x, 3)\n",
        "z.grad_value = 1.0\n",
        "\n",
        "print('value of x-y + pow(x,3) evaluated at x=0.5, y=4.2: {}\\nforward pass of our implementation: {}'.format(0.5 - 4.2 + (0.5)**3, z.value))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "value of x-y + pow(x,3) evaluated at x=0.5, y=4.2: -3.575\n",
            "forward pass of our implementation: -3.575\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNJAX6XloNAk",
        "outputId": "cfed0cd9-50a5-4f9d-bd33-79577c7c8398",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Another example\n",
        "x = Var(0.5)\n",
        "y = Var(4.2)\n",
        "z = log(y - x) + sin(pow(x, 3) + y)\n",
        "z.grad_value = 1.0\n",
        "\n",
        "print('value of log(y-x) + sin(pow(x,3)+y) evaluated at x=0.5, y=4.2: {}\\nforward pass of our implementation: {}'.format(0.382434, z.value))\n",
        "y.grad()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "value of log(y-x) + sin(pow(x,3)+y) evaluated at x=0.5, y=4.2: 0.382434\n",
            "forward pass of our implementation: 0.38243423425794165\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.2426370310823537"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NOk5Hp3arEH",
        "outputId": "8d6111e8-49ad-454b-c8f6-6a42ace77388",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "¬£x = Var(0.5)\n",
        "y = Var(4.2)\n",
        "z = x * y + sin(x)\n",
        "z.grad_value = 1.0\n",
        "\n",
        "print('value of x*y + sin(x) evaluated at x=0.5, y=4.2: {}\\nforward pass of our implementation: {}'.format(0.5 * 4.2 + np.sin(0.5), z.value))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "value of x*y + sin(x) evaluated at x=0.5, y=4.2: 2.579425538604203\n",
            "forward pass of our implementation: 2.579425538604203\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8_xFjwZasJ9",
        "outputId": "afbb5666-54b3-4fe6-b5a4-031fecdd8bba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x.grad()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKwnUnZYayF-",
        "outputId": "1cc9f30d-2a11-4a66-bf95-faab2366028c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print('value of dz/dx = y + cos(x) evaluated at x=0.5, y=4.2: {}\\nreverse pass of our implementation: {}'.format(4.2 + np.cos(0.5), x.grad_value))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "value of dz/dx = y + cos(x) evaluated at x=0.5, y=4.2: 5.077582561890373\n",
            "reverse pass of our implementation: 1.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2iaw8BGfi40H"
      },
      "source": [
        "**Exercise 6:** Using your implementations of forward and reverse mode AutoDiff, implement automatic second order derivatives."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q44TICcpd3RF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkYABDaVefY5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}